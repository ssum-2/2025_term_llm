import os, base64, requests, json, re
import fitz  # PyMuPDF
import pdfplumber
import pandas as pd
from PIL import Image
from collections import defaultdict
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_core.documents import Document
from tenacity import retry, stop_after_attempt, wait_exponential
from langchain_core.language_models.chat_models import BaseChatModel
from langchain_core.prompts import ChatPromptTemplate
from openai import OpenAI
from typing import List, Dict, Any, Optional


class LayoutAnalyzer:
    """Upstage Layout Analysis APIë¥¼ í˜¸ì¶œí•˜ì—¬ PDFì˜ êµ¬ì¡°ë¥¼ ë¶„ì„í•˜ëŠ” í´ë˜ìŠ¤"""
    def __init__(self, api_key: str):
        self.api_key = api_key
        self.api_url = "https://api.upstage.ai/v1/document-ai/layout-analysis"

    @retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=2, max=10))
    def analyze(self, pdf_path: str) -> Optional[Dict[str, Any]]:
        """APIë¥¼ í˜¸ì¶œí•˜ì—¬ ë ˆì´ì•„ì›ƒ ë¶„ì„ì„ ìˆ˜í–‰í•˜ê³  ê²°ê³¼ë¥¼ JSONìœ¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤."""
        headers = {"Authorization": f"Bearer {self.api_key}"}
        try:
            with open(pdf_path, "rb") as f:
                files = {"document": f}
                response = requests.post(self.api_url, headers=headers, files=files)
            response.raise_for_status()
            return response.json()
        except requests.exceptions.RequestException as e:
            print(f"âŒ [API Error] Layout Analysis API í˜¸ì¶œ ì‹¤íŒ¨ ({pdf_path}): {e}")
            return None


def crop_element_from_pdf(pdf_path: str, page_num: int, bbox: List[Dict[str, float]], output_folder: str,
                          element_id: str) -> str:
    """PDF í˜ì´ì§€ì—ì„œ íŠ¹ì • bounding box ì˜ì—­ì„ ì´ë¯¸ì§€ë¡œ ì˜ë¼ë‚´ ì €ì¥í•©ë‹ˆë‹¤."""
    output_path = os.path.join(output_folder, f"element_{element_id}.png")
    os.makedirs(output_folder, exist_ok=True)

    try:
        doc = fitz.open(pdf_path)
        page = doc.load_page(page_num - 1)

        x0, y0 = bbox[0]['x'], bbox[0]['y']
        x1, y1 = bbox[2]['x'], bbox[2]['y']

        rect = fitz.Rect(x0, y0, x1, y1)
        clip_rect = rect & page.rect
        if not clip_rect.is_empty:
            pix = page.get_pixmap(clip=clip_rect, dpi=200)
            pix.save(output_path)
        else:
            return ""
        doc.close()
        return output_path
    except Exception as e:
        print(f"âŒ [Cropping Error] Element {element_id} ì´ë¯¸ì§€ ìë¥´ê¸° ì‹¤íŒ¨: {e}")
        return ""


def parse_pdf_advanced(pdf_path: str, api_key: str) -> Dict[str, Any]:
    """Layout Analysis APIë¥¼ ì‚¬ìš©í•˜ì—¬ PDFë¥¼ íŒŒì‹±í•˜ê³  êµ¬ì¡°í™”ëœ ìš”ì†Œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    print(f"ğŸš€ [Parser] '{os.path.basename(pdf_path)}'ì˜ ì´ˆê°•ë ¥ ë¶„ì„ ì‹œì‘...")

    analyzer = LayoutAnalyzer(api_key)
    analysis_result = analyzer.analyze(pdf_path)
    if not analysis_result or "elements" not in analysis_result:
        print(f"âš ï¸ [Parser] '{os.path.basename(pdf_path)}' ë¶„ì„ ì‹¤íŒ¨ ë˜ëŠ” ê²°ê³¼ ì—†ìŒ.")
        return {"elements_by_page": {}, "author": "ì‘ì„±ì"}

    elements_by_page = defaultdict(list)
    for element in analysis_result["elements"]:
        elements_by_page[element.get("page", 1)].append(element)

    author = "ì‘ì„±ì"
    if 1 in elements_by_page:
        first_page_text = " ".join([elem.get('text', '') for elem in elements_by_page[1]])
        match = re.search(r'([\w\s]+(?:ì¦ê¶Œ|íˆ¬ìì¦ê¶Œ|ìì‚°ìš´ìš©|ê²½ì œì—°êµ¬ì†Œ|ë¦¬ì„œì¹˜))', first_page_text)
        if match:
            author = match.group(1).strip().replace("\n", " ")

    output_folder = os.path.join("./tmp/elements", os.path.splitext(os.path.basename(pdf_path))[0])
    for page_num, elements in elements_by_page.items():
        for elem in elements:
            if elem.get('category') in ['figure', 'table']:
                cropped_path = crop_element_from_pdf(
                    pdf_path=pdf_path, page_num=page_num, bbox=elem['bounding_box'],
                    output_folder=output_folder, element_id=elem['id']
                )
                elem['cropped_image_path'] = cropped_path

    return {"elements_by_page": dict(elements_by_page), "author": author}


@retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=2, min=4, max=10))
def summarize_element_advanced(element: Dict, context_text: str, llm: BaseChatModel,
                               openai_client: Optional[OpenAI] = None) -> str:
    """êµ¬ì¡°í™”ëœ ìš”ì†Œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì»¨í…ìŠ¤íŠ¸ë¥¼ ê³ ë ¤í•˜ì—¬ ìš”ì•½ë¬¸ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    category = element.get("category")

    try:
        if category in ['title', 'header', 'paragraph', 'list']:
            prompt = ChatPromptTemplate.from_template("ë‹¤ìŒì€ ê¸ˆìœµ ë¦¬í¬íŠ¸ì˜ ì¼ë¶€ì…ë‹ˆë‹¤. í•µì‹¬ ë‚´ìš©ì„ 1-2 ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ìš”ì•½í•˜ì„¸ìš”:\n\n{content}")
            chain = prompt | llm
            return chain.invoke({"content": element.get('text', '')}).content

        elif category in ['figure', 'table']:
            image_path = element.get('cropped_image_path')
            if not image_path or not os.path.exists(image_path) or not openai_client:
                return f"[{category.capitalize()} ìš”ì•½ ìƒëµ: ì´ë¯¸ì§€ íŒŒì¼ ì—†ìŒ]"

            with open(image_path, "rb") as f:
                img_b64 = base64.b64encode(f.read()).decode()

            prompt_text = (f"ë‹¹ì‹ ì€ ê¸ˆìœµ ë°ì´í„° ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒì€ ë¦¬í¬íŠ¸ì˜ ì¼ë¶€ í…ìŠ¤íŠ¸ ì»¨í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ì…ë‹ˆë‹¤."
                           f"ì´ë¯¸ì§€({category})ì˜ í•µì‹¬ ë‚´ìš©ê³¼ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì¢…í•©í•˜ì—¬ ê°€ì¥ ì¤‘ìš”í•œ ì •ë³´ë¥¼ ìš”ì•½í•´ì£¼ì„¸ìš”.\n\n"
                           f"## ì£¼ë³€ í…ìŠ¤íŠ¸ ì»¨í…ìŠ¤íŠ¸:\n{context_text}\n\n"
                           f"## ë¶„ì„ ëŒ€ìƒ ì´ë¯¸ì§€({category}):")

            response = openai_client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": [
                    {"type": "text", "text": prompt_text},
                    {"type": "image_url", "image_url": {"url": f"data:image/png;base64,{img_b64}"}}
                ]}],
                max_tokens=500
            )
            return response.choices[0].message.content

        else:
            return ""
    except Exception as e:
        print(f"âŒ [{category} ìš”ì•½ ì˜¤ë¥˜] {e}")
        return f"[{category} ìš”ì•½ ì¤‘ ì˜¤ë¥˜ ë°œìƒ]"
def parse_pdf(pdf_path):
    elements = []
    print(f"[parse_pdf] í˜¸ì¶œë¨, pdf_path: {pdf_path}")
    doc = fitz.open(pdf_path)
    all_text = ""
    for page_num, page in enumerate(doc):
        text = page.get_text()
        if text.strip():
            all_text += text + "\n\n"
        try:
            tables = page.find_tables()
            if tables and tables.tables:
                for t in tables:
                    md = t.to_markdown()
                    elements.append({'type': 'table', 'content': md, 'page': page_num + 1})
        except Exception:
            pass

        # ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs('./tmp/images', exist_ok=True)
        for img_index, img in enumerate(page.get_images(full=True)):
            xref = img[0] if isinstance(img, tuple) else img
            base_image = doc.extract_image(xref)
            if base_image:
                image_bytes = base_image["image"]
                image_ext = base_image["ext"]
                image_path = f"./tmp/images/tmp_page{page_num + 1}_img{img_index + 1}.{image_ext}"
                with open(image_path, "wb") as f:
                    f.write(image_bytes)
                elements.append({'type': 'image', 'content': image_path, 'page': page_num + 1})

    if all_text.strip():
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1200, chunk_overlap=200, separators=["\n\n\n", "\n\n", "\n", ". ", " "]
        )
        split_texts = text_splitter.split_text(all_text)
        for idx, chunk in enumerate(split_texts):
            elements.append({'type': 'text', 'content': chunk, 'page': f"chunk_{idx + 1}"})

    with pdfplumber.open(pdf_path) as pdf:
        for page_num, page in enumerate(pdf.pages):
            try:
                tables = page.extract_tables()
                for t in tables:
                    if t:
                        df = pd.DataFrame(t[1:], columns=t[0])
                        md = df.to_markdown(index=False)
                        elements.append({'type': 'table', 'content': md, 'page': page_num + 1})
            except Exception:
                pass

    print(f"[parse_pdf] ì¢…ë£Œë¨, elements ê°œìˆ˜: {len(elements)}")
    return elements


@retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=2, min=4, max=10))
def summarize_single_element(element: dict) -> Document | None:
    """ì¸ìë¡œ ë°›ì€ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ìš”ì†Œë¥¼ ìš”ì•½í•©ë‹ˆë‹¤."""
    elem_type = element.get("type")
    content = element.get("content")
    page = element.get("page")
    mode = element.get("mode")
    pdf_path = element.get("pdf_path")
    # ì¸ìì—ì„œ ëª¨ë¸ ê°€ì ¸ì˜¤ê¸°
    llm: BaseChatModel = element.get("llm")
    openai_client: OpenAI | None = element.get("openai_client")

    if not llm:
        print(f"[ERROR] LLM instance not provided for summarization (Page: {page}).")
        return None

    source_file = os.path.basename(pdf_path)
    print(f"[{os.getpid()}] summarize_single_element: page {page} ({elem_type}) ìš”ì•½ ì‹œì‘")
    summary_text = ""
    metadata = {"source_file": source_file, "page": page, "element_type": elem_type}

    try:
        if elem_type == "text":
            prompt = ChatPromptTemplate.from_template("ë‹¤ìŒì€ ê¸ˆìœµ ë¦¬í¬íŠ¸ì˜ ì¼ë¶€ì…ë‹ˆë‹¤. í•µì‹¬ ë‚´ìš©ì„ í•œë‘ ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ìš”ì•½í•˜ì„¸ìš”:\n\n{content}")
            chain = prompt | llm
            summary_text = chain.invoke({"content": content}).content

        elif elem_type == "table":
            prompt = ChatPromptTemplate.from_template("ë‹¤ìŒì€ ê¸ˆìœµ ë¦¬í¬íŠ¸ì˜ í‘œì…ë‹ˆë‹¤. ì´ í‘œê°€ ì˜ë¯¸í•˜ëŠ” í•µì‹¬ ì •ë³´ì™€ ìˆ˜ì¹˜ë¥¼ ìš”ì•½í•˜ì„¸ìš”:\n\n{content}")
            chain = prompt | llm
            summary_text = chain.invoke({"content": content}).content

        elif elem_type == "image":
            if mode != "openai" or not openai_client:
                summary_text = f"[INFO] Image captioning skipped (Mode: {mode}, Client: {'OK' if openai_client else 'Not OK'})."
            else:
                summary_text = caption_images(content, openai_client)

        else:
            print(f"ì•Œ ìˆ˜ ì—†ëŠ” ìš”ì†Œ íƒ€ì… ë°œê²¬: {elem_type}")
            return None

    except Exception as e:
        print(f"[ERROR] LLM ìš”ì•½ ì‹¤íŒ¨ (Page: {page}): {str(e)}")
        summary_text = f"[ERROR] LLM ìš”ì•½ ì‹¤íŒ¨ (Page: {page}): {str(e)}"

    return Document(page_content=summary_text, metadata=metadata)


def caption_images(image_path: str, client: OpenAI) -> str:
    """ì¸ìë¡œ ë°›ì€ OpenAI í´ë¼ì´ì–¸íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ ìº¡ì…˜ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    with open(image_path, "rb") as f:
        img_b64 = base64.b64encode(f.read()).decode()

    prompt = "ì´ ì´ë¯¸ì§€ë¥¼ ì„¤ëª…í•˜ëŠ” í•œê¸€ ìº¡ì…˜ì„ ìƒì„±í•˜ì„¸ìš”. ê¸ˆìœµ/ì¦ê¶Œ ë¦¬í¬íŠ¸ì˜ ì°¨íŠ¸ ë˜ëŠ” ê·¸ë˜í”„ì¼ ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤."
    response = client.chat.completions.create(
        model="gpt-4-vision-preview",
        messages=[
            {"role": "user", "content": [
                {"type": "text", "text": prompt},
                {"type": "image_url", "image_url": f"data:image/png;base64,{img_b64}"}
            ]}
        ],
        max_tokens=100
    )
    return response.choices[0].message.content