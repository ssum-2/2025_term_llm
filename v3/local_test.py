# local_test.py (ìˆ˜ì •)
import asyncio
import os

os.environ["KMP_DUPLICATE_LIB_OK"] = "TRUE"
from dotenv import load_dotenv

load_dotenv()
from dependencies import get_llm, get_mini_llm, get_reranker, get_openai_client
from utils import parse_pdf
from chains import build_preinsight_chain
from financial import get_financial_timeseries_data_for_llm, get_all_tickers
from news_crawler import get_latest_news, summarize_news_async
from rag import advanced_rag_search
from vector_db import save_to_vector_db, clear_vector_db, search_vector_db

# --- í…ŒìŠ¤íŠ¸ ì„¤ì • ---
TEST_PDF_PATH = "./AnalReports/samsung_report.pdf"  # ğŸ‘ˆ í…ŒìŠ¤íŠ¸í•  PDF ê²½ë¡œ
TEST_STOCK_NAME = "ì‚¼ì„±ì „ì"
TEST_TICKER = "005930"
TEST_QUERY = "ì‚¼ì„±ì „ìì˜ HBM ì‚¬ì—… ì „ë§ê³¼ ë¦¬ìŠ¤í¬ëŠ” ë¬´ì—‡ì¸ê°€?"


# -----------------

async def test_01_pdf_processing():
    print("\n--- ğŸ§ª í…ŒìŠ¤íŠ¸ 1: PDF ì²˜ë¦¬ (ìš”ì•½+ì •ë³´ì¶”ì¶œ) ë° ì„ë² ë”© ---")
    if not os.path.exists(TEST_PDF_PATH):
        print(f"'{TEST_PDF_PATH}' íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. í…ŒìŠ¤íŠ¸ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
        return

    # í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ëª¨ë¸ ì§ì ‘ ë¡œë“œ
    mini_llm = get_mini_llm()
    openai_client = get_openai_client()

    clear_vector_db()
    from graph_workflow import _summarize_elements_in_parallel

    elements = parse_pdf(TEST_PDF_PATH)
    state = {
        "elements": elements,
        "pdf_path": TEST_PDF_PATH,
        "mode": os.getenv("LLM_MODE", "solar"),
        "semaphore": asyncio.Semaphore(5),
        "processed_docs": [],
        "llm": mini_llm,  # ëª¨ë¸ ì „ë‹¬
        "openai_client": openai_client  # ëª¨ë¸ ì „ë‹¬
    }

    processed_docs = await _summarize_elements_in_parallel(state)
    print(f"\n[ì²˜ë¦¬ ê²°ê³¼] ì´ {len(processed_docs)}ê°œì˜ ë¬¸ì„œ/ì •ë³´ ìƒì„±")

    summary_count = sum(1 for d in processed_docs if d.metadata.get('element_type') != 'broker_info')
    broker_info_count = sum(1 for d in processed_docs if d.metadata.get('element_type') == 'broker_info')
    print(f"  - ìš”ì•½ ë¬¸ì„œ: {summary_count}ê°œ")
    print(f"  - ì¶”ì¶œëœ ì¦ê¶Œì‚¬ ì •ë³´: {broker_info_count}ê°œ")

    if broker_info_count > 0:
        print("\n[ì¶”ì¶œëœ ì •ë³´ ì˜ˆì‹œ]")
        for doc in processed_docs:
            if doc.metadata.get('element_type') == 'broker_info':
                print(doc.page_content)
                break

    await save_to_vector_db(processed_docs)


async def test_02_financial_data_and_news():
    print(f"\n--- ğŸ§ª í…ŒìŠ¤íŠ¸ 2: '{TEST_STOCK_NAME}' ì¬ë¬´ ë°ì´í„° ë° ë‰´ìŠ¤ ì¡°íšŒ ---")
    financial_data = get_financial_timeseries_data_for_llm(TEST_TICKER, years=1)
    print("\n[ì¬ë¬´ ë°ì´í„° (ìµœê·¼ 3ê°œì›”)]")
    if financial_data and financial_data.price:
        price_dict = financial_data.model_dump()['price']
        per_dict = financial_data.model_dump()['per']
        pbr_dict = financial_data.model_dump()['pbr']
        for date in sorted(list(price_dict.keys()))[-3:]:
            print(f"  - {date}: ì£¼ê°€={price_dict.get(date)}, PER={per_dict.get(date)}, PBR={pbr_dict.get(date)}")
    else:
        print("ì¬ë¬´ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

    articles = await asyncio.to_thread(get_latest_news, TEST_STOCK_NAME)
    print("\n[ìµœì‹  ë‰´ìŠ¤ ê¸°ì‚¬]")
    if articles:
        for article in articles[:2]:
            print(f"- {article['title']} ({article['publisher']})")

        mini_llm = get_mini_llm()
        news_summary = await summarize_news_async(articles, mini_llm)
        print("\n[ë‰´ìŠ¤ ìš”ì•½]")
        print(news_summary)
    else:
        print("ìµœì‹  ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")


async def test_03_advanced_rag_pipeline():
    print("\n--- ğŸ§ª í…ŒìŠ¤íŠ¸ 3: ê³ ë„í™”ëœ RAG íŒŒì´í”„ë¼ì¸ (ë¶„ë¦¬ ê²€ìƒ‰) ---")
    # Vector DBì— ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸í•˜ëŠ” ë¡œì§ ìˆ˜ì • (get_all_tickersëŠ” KRX ì¢…ëª© ëª©ë¡ì„ ê°€ì ¸ì˜¤ë¯€ë¡œ ë¶€ì ì ˆ)
    try:
        if not search_vector_db("test", k=1):
            print("Vector DBê°€ ë¹„ì–´ìˆì–´ RAG í…ŒìŠ¤íŠ¸ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤. ë¨¼ì € test_01_pdf_processingì„ ì‹¤í–‰í•˜ì„¸ìš”.")
            return
    except Exception:
        print("Vector DBê°€ ë¹„ì–´ìˆì–´ RAG í…ŒìŠ¤íŠ¸ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤. ë¨¼ì € test_01_pdf_processingì„ ì‹¤í–‰í•˜ì„¸ìš”.")
        return

    print(f"\n[RAG í…ŒìŠ¤íŠ¸] ì§ˆë¬¸: {TEST_QUERY}")

    mini_llm = get_mini_llm()
    reranker = get_reranker()

    general_docs = await advanced_rag_search(TEST_QUERY, k=5, llm=mini_llm, reranker=reranker)
    print(f"\n[ì¼ë°˜ ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰ ê²°ê³¼ {len(general_docs)}ê°œ]")
    for i, doc in enumerate(general_docs):
        print(f"  - Doc {i + 1}: {doc.page_content[:80]}...")

    broker_docs = search_vector_db(TEST_QUERY, k=5, filter_criteria={"element_type": "broker_info"})
    print(f"\n[ì¦ê¶Œì‚¬ ì˜ê²¬ ê²€ìƒ‰ ê²°ê³¼ {len(broker_docs)}ê°œ]")
    for i, doc in enumerate(broker_docs):
        print(f"  - Card {i + 1}: {doc.page_content.replace(chr(10), ' ')}")


async def test_04_preinsight_chain():
    print("\n--- ğŸ§ª í…ŒìŠ¤íŠ¸ 4: Pre-insight ì²´ì¸ (êµ¬ì¡°í™” ë°ì´í„° ê¸°ë°˜) ---")
    broker_docs = search_vector_db("", k=15, filter_criteria={"element_type": "broker_info"})
    if not broker_docs:
        print("ì¶”ì¶œëœ ì¦ê¶Œì‚¬ ì •ë³´ê°€ ì—†ì–´ Pre-insight í…ŒìŠ¤íŠ¸ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
        return

    context = "\n---\n".join([d.page_content for d in broker_docs])
    financial_data = get_financial_timeseries_data_for_llm(TEST_TICKER).model_dump()

    articles = await asyncio.to_thread(get_latest_news, TEST_STOCK_NAME, max_results=5)
    news_titles = "\n".join([f"- {a['title']}" for a in articles]) if articles else "ìµœì‹  ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤."

    mini_llm = get_mini_llm()
    chain = build_preinsight_chain(mini_llm)
    insight = await chain.ainvoke({
        "context": context,
        "financial": financial_data,
        "news_titles": news_titles
    })
    print("\n[Pre-insight ìƒì„± ê²°ê³¼]")
    print("í•˜ì´ë¼ì´íŠ¸:")
    for h in insight.highlights:
        print(f"- {h}")
    print("\nì¶”ì²œ ì§ˆë¬¸:")
    for q in insight.suggested_questions:
        print(f"- {q}")


async def main():
    print("KRX í‹°ì»¤ ëª©ë¡ ë¡œë”© ì¤‘...")
    get_all_tickers()

    # í…ŒìŠ¤íŠ¸ì— í•„ìš”í•œ ëª¨ë¸ ë¯¸ë¦¬ ë¡œë”©
    print("Pre-loading models for test...")
    get_llm()
    get_mini_llm()
    get_reranker()
    get_openai_client()

    await test_01_pdf_processing()
    await test_02_financial_data_and_news()
    await test_03_advanced_rag_pipeline()
    await test_04_preinsight_chain()


if __name__ == "__main__":
    if not os.path.exists("./AnalReports"):
        os.makedirs("./AnalReports")
        print("ê²½ê³ : './AnalReports' í´ë”ê°€ ì—†ì–´ ìƒˆë¡œ ìƒì„±í–ˆìŠµë‹ˆë‹¤. í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ í•´ë‹¹ í´ë”ì— PDF íŒŒì¼ì„ ë„£ì–´ì£¼ì„¸ìš”.")

    asyncio.run(main())